{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic packages\n",
    "import os, math, csv, scipy, time, random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Model Preprocessing\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    RobustScaler,\n",
    "    MaxAbsScaler,\n",
    "    QuantileTransformer,\n",
    "    PowerTransformer,\n",
    "    Normalizer,\n",
    "    Binarizer\n",
    ")\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Model selection/evaluation\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_predict,\n",
    "    cross_val_score,\n",
    "    cross_val_predict,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    KFold,\n",
    "    cross_validate,\n",
    "    learning_curve,\n",
    "    LeaveOneOut,\n",
    ")\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning\n",
    "#Regressor functions\n",
    "\n",
    "# import xgboost as xgb\n",
    "\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.ensemble as ens\n",
    "#SGD regressor, Lasso, ElasticNet, Ridgeregression, SVR(kernel='linear'), SVT(kernel='rbf'), Ensemble Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = (\n",
    "    \"/Users/Training_Data_3.xlsx\"\n",
    ")\n",
    "\n",
    "df = pd.read_excel(training_data, index_col=\"Molecule\").dropna()\n",
    "\n",
    "df.drop(columns=[\"Isoelectric charge @5.5 pH\", \"Lipophilicity (Log D @ 5.5 pH)\",\\\n",
    "    \"Vapor Pressure (mm Hg at 25 Â°C)\", \"logkp (cm/s)\", \"mg/mL @ pH 5.5\"], inplace=True)\n",
    "# Split data into input and predicted variables\n",
    "\n",
    "y = df[\"JSS\"]\n",
    "X = df.drop([\"JSS\"], axis=1)\n",
    "\n",
    "# split data into training and testing sets\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# look at z-scored distribution of data\n",
    "\n",
    "# df_z = df.apply(stats.zscore)\n",
    "# df_z.plot(kind=\"kde\", subplots=True, figsize=(5, 20), sharex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corrwith(df[\"JSS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [\n",
    "    ens.GradientBoostingRegressor(),\n",
    "    ens.ExtraTreesRegressor(),\n",
    "    ens.RandomForestRegressor(),\n",
    "    ens.AdaBoostRegressor(),\n",
    "    ens.BaggingRegressor(),\n",
    "    lm.LinearRegression(),\n",
    "    lm.Lasso(),\n",
    "    lm.Ridge(),\n",
    "    lm.ElasticNet(),\n",
    "    lm.SGDRegressor()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary of models with parameters for GridSearchCV\n",
    "gbr_params = {\n",
    "        # 'gbr': ens.GradientBoostingRegressor(),\n",
    "        'gbr__loss': ('ls', 'lad', 'huber', 'quantile'),\n",
    "        # 'gbr__learning_rate': (0.1, 0.05, 0.02, 0.01),\n",
    "        'gbr_n_estimators': (100, 200, 300, 400, 500),\n",
    "        'gbr_max_depth': (1,3,5,7,9),\n",
    "        'gbr_min_samples_leaf': (0.01,1,100)\n",
    "    }\n",
    "etr_params = {\n",
    "        # 'etr': (ens.ExtraTreesRegressor()),\n",
    "        # 'etr_scalers': scalers,\n",
    "        'etr__n_estimators': (10, 30),\n",
    "        'etr_max_depth': (1,2,3,4,5,6,7,8,9,10),\n",
    "        'etr_min_samples_split': (0.001,0.01,0.1,1,10,100),\n",
    "        'etr_min_samples_leaf': (0.001,0.01,0.1,1,10,100),\n",
    "        'etr_min_weight_fraction_leaf': (0.001,0.01,0.1,1,10,100),\n",
    "        'etr_max_features': ('auto', 'sqrt', 'log2'),\n",
    "        'etr_max_leaf_nodes': (None, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100),\n",
    "        'etr_min_impurity_decrease': (0.001,0.01,0.1,1,10,100)}\n",
    "\n",
    "rfr_params = {\n",
    "        'rfr': (ens.RandomForestRegressor()),\n",
    "        # 'rfr_scalers': scalers,\n",
    "        'rfr__n_estimators':[100, 200, 300, 400, 500],\n",
    "        'rfr_max_depth': (1,2,3,4,5,6,7,8,9,10),\n",
    "        'rfr_min_samples_split': (0.001,0.01,0.1,1,10,100),\n",
    "        'rfr_min_samples_leaf': (0.001,0.01,0.1,1,10,100),\n",
    "        'rfr_min_weight_fraction_leaf': (0.001,0.01,0.1,1,10,100),\n",
    "        'rfr_max_features': ('auto', 'sqrt', 'log2'),\n",
    "        'rfr_max_leaf_nodes': (None, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100),\n",
    "        'rfr_min_impurity_decrease': (0.001,0.01,0.1,1,10,100)}\n",
    "ada_params = {\n",
    "        'clf': (ens.AdaBoostRegressor()),\n",
    "        # 'clf_scalers': scalers,\n",
    "        'clf_base_estimator': (lm.LinearRegression(), lm.Lasso(), lm.Ridge(), lm.ElasticNet(), lm.SGDRegressor(), ens.BaggingRegressor()),\n",
    "        'clf_n_estimators': [100, 200, 300, 400, 500],\n",
    "        'clf_learning_rate': (0.1, 0.01, 0.001),\n",
    "        'clf_loss': ('linear', 'square', 'exponential')}\n",
    "bag_params = {\n",
    "        'clf': (ens.BaggingRegressor(),),\n",
    "        # 'clf_scalers': scalers,\n",
    "        'clf_base_estimator': (lm.LinearRegression(), lm.Lasso(), lm.Ridge(), lm.ElasticNet(), lm.SGDRegressor(), ens.BaggingRegressor()),\n",
    "        'clf_n_estimators': [100, 200, 300, 400, 500],\n",
    "        'clf_max_samples': (0.001,0.01,0.1,1,10,100),\n",
    "        'clf_max_features': (0.001,0.01,0.1,1,10,100),\n",
    "        'clf_bootstrap': (True, False),\n",
    "        'clf_bootstrap_features': (True, False),\n",
    "        'clf_oob_score': (True, False),\n",
    "        'clf_warm_start': (True, False),\n",
    "        'clf_n_jobs': (1,2,3,4,5,6,7,8,9,10)}\n",
    "lr_params = {\n",
    "        'clf': (lm.LinearRegression()),\n",
    "        # 'clf_scalers': scalers,\n",
    "        'clf__fit_intercept': (True, False),\n",
    "        'clf__normalize': (True, False),\n",
    "        'clf__copy_X': (True, False),\n",
    "        'clf__n_jobs': (1,2,3,4,5,6,7,8,9,10)\n",
    "        }\n",
    "lasso_params = {\n",
    "        'clf': (lm.Lasso()),\n",
    "        # 'clf_scalers': scalers,\n",
    "        'clf__alpha': (0.1, 0.01, 0.001),\n",
    "        'clf__fit_intercept': (True, False),\n",
    "        'clf__normalize': (True, False),\n",
    "        'clf__precompute': (True, False),\n",
    "        'clf__copy_X': (True, False),\n",
    "        'clf__max_iter': (100, 200, 300, 400, 500),\n",
    "        'clf__tol': (0.001, 0.0001, 0.00001),\n",
    "        'clf__warm_start': (True, False),\n",
    "        'clf__positive': (True, False),\n",
    "        'clf__selection': ('cyclic', 'random'),\n",
    "    }\n",
    "ridge_params = {\n",
    "        'clf': (lm.Ridge()),\n",
    "        # 'clf_scalers': scalers,\n",
    "        'clf__alpha': (0.1, 0.01, 0.001),\n",
    "        'clf__fit_intercept': (True, False),\n",
    "        'clf__normalize': (True, False),\n",
    "        'clf__copy_X': (True, False),\n",
    "        'clf__max_iter': (100, 200, 300, 400, 500),\n",
    "        'clf__tol': (0.001, 0.0001, 0.00001),\n",
    "        'clf__solver': ('auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'),\n",
    "    }\n",
    "enet_params = {\n",
    "        'clf': (lm.ElasticNet()),\n",
    "        # 'clf_scalers': scalers,\n",
    "        'clf__alpha': (0.1, 0.01, 0.001),\n",
    "        'clf__l1_ratio': (0.1, 0.01, 0.001),\n",
    "        'clf__fit_intercept': (True, False),\n",
    "        'clf__normalize': (True, False),\n",
    "        'clf__precompute': (True, False),\n",
    "        'clf__copy_X': (True, False),\n",
    "        'clf__max_iter': (100, 200, 300, 400, 500),\n",
    "        'clf__tol': (0.001, 0.0001, 0.00001),\n",
    "        'clf__warm_start': (True, False),\n",
    "        'clf__positive': (True, False),\n",
    "        'clf__selection': ('cyclic', 'random'),\n",
    "    }\n",
    "sgd_params = {\n",
    "        'clf': lm.SGDRegressor(),\n",
    "        # 'clf_scalers': scalers,\n",
    "        'clf__loss': ('squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'),\n",
    "        'clf__penalty': ('l2', 'l1', 'elasticnet'),\n",
    "        'clf__alpha': (0.1, 0.01, 0.001),\n",
    "        'clf__l1_ratio': (0.1, 0.01, 0.001),\n",
    "        'clf__fit_intercept': (True, False),\n",
    "        'clf__max_iter': (100, 200, 300, 400, 500),\n",
    "        'clf__tol': (0.001, 0.0001, 0.00001),\n",
    "        'clf__shuffle': (True, False),\n",
    "        'clf__verbose': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10),\n",
    "        'clf__epsilon': (0.1, 0.01, 0.001),\n",
    "        'clf__random_state': (None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10),\n",
    "        'clf__learning_rate': ('constant', 'optimal', 'invscaling', 'adaptive'),\n",
    "        'clf__eta0': (0.1, 0.01, 0.001),\n",
    "        'clf__power_t': (0.1, 0.01, 0.001),\n",
    "        'clf__early_stopping': (True, False),\n",
    "        'clf__validation_fraction': (0.1, 0.01, 0.001),\n",
    "        'clf__n_iter_no_change': (1, 2, 3, 4, 5, 6, 7, 8, 9, 10),\n",
    "        'clf__warm_start': (True, False),\n",
    "        'clf__average': (True, False)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('Transform_Step', RobustScaler()),\n",
    "    ('Model_step', regressors)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_gb_reg = GridSearchCV(pipeline, param_grid=gbr_params, scoring='r2', cv=2, n_jobs=-1)\n",
    "gs_gb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add iterative imputer to fill missing values\n",
    "# add PCA to reduce dimensionality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search the entire pipeline\n",
    "\n",
    "# g_search = GridSearchCV(pipeline, cv = 10, scoring = 'r2')\n",
    "# g_search.fit(X_train, y_train)\n",
    "# g_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validate the Entire Pipeline\n",
    "\n",
    "cross_val_score(pipeline, X_train, y_train, cv=10, scoring='r2').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting and predicting the pipeline\n",
    "model = ens.ExtraTreesRegressor(n_estimators = 50)\n",
    "model.fit(X_train, y_train)\n",
    "model.predict(X_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoring the pipeline\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to determine JSS value with input values, this is the final goal, to input a molecules parameters and get the JSS value\n",
    "\n",
    "# # Printing coefficients and intercept to create function later\n",
    "# print('Model_step'.coef_)\n",
    "# print(.intercept_)\n",
    "\n",
    "\n",
    "coefficients = pipe.coef_\n",
    "intercept = pipe.intercept_\n",
    "def calculate_JSS(MW_in, MP_in, Sol_in, Iso_in, Lipo_in, Vapo_in, logkp_in):\n",
    "  return (MW_in * coefficients[0]) + (MP_in * coefficients[1]) + (Sol_in * coefficients[2]) + (Iso_in * coefficients[3]) \\\n",
    "  + (Lipo_in * coefficients[4]) + (Vapo_in * coefficients[5]) + (logkp_in * coefficients[6])+ intercept"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
